\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{fancyhdr}
\usepackage{float}
\usepackage{subcaption}
\usepackage{array}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{colortbl}
\usetikzlibrary{shapes.geometric,arrows,positioning,calc}

\geometry{left=2cm,right=2cm,top=2.5cm,bottom=2.5cm}

% Configuration des couleurs
\definecolor{primaryblue}{RGB}{37,99,235}
\definecolor{secondaryblue}{RGB}{59,130,246}
\definecolor{lightblue}{RGB}{219,234,254}
\definecolor{darkgray}{RGB}{55,65,81}
\definecolor{lightgray}{RGB}{243,244,246}
\definecolor{green}{RGB}{16,185,129}
\definecolor{orange}{RGB}{245,158,11}
\definecolor{red}{RGB}{239,68,68}

% En-têtes et pieds de page
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\textcolor{primaryblue}{\textbf{AI Learning Assistant}}}
\fancyhead[R]{\textcolor{darkgray}{\thepage}}
\fancyfoot[C]{\textcolor{darkgray}{\small Rapport Technique - Système de Suivi Intelligent}}

% Titre
\title{\Huge\textbf{\textcolor{primaryblue}{AI Learning Assistant}}\\
\Large\textcolor{darkgray}{Système Intelligent de Suivi des Étudiants}\\
\large\textcolor{darkgray}{Rapport Technique Complet}}

\author{\textbf{Équipe de Développement}\\
\textcolor{darkgray}{Projet d'Intelligence Artificielle Éducative}}

\date{\textcolor{darkgray}{\today}}

\begin{document}

\maketitle
\thispagestyle{empty}

\newpage
\tableofcontents
\newpage

\section{Introduction}

\subsection{Contexte et Objectifs}

L'AI Learning Assistant est un système innovant conçu pour révolutionner l'expérience éducative en intégrant des technologies d'intelligence artificielle avancées. Ce système offre une solution complète pour le suivi en temps réel des étudiants, l'analyse comportementale, et la détection d'objets perturbateurs dans l'environnement d'apprentissage.

Le système vise à :
\begin{itemize}
    \item Améliorer la concentration et l'engagement des étudiants
    \item Fournir des analyses détaillées aux enseignants
    \item Détecter automatiquement les éléments de distraction
    \item Offrir une interface intuitive pour la gestion des données
    \item Intégrer des fonctionnalités de traduction de langue des signes (en développement)
\end{itemize}

\subsection{Technologies Utilisées}

Le système s'appuie sur un ensemble de technologies modernes et robustes :

\begin{table}[H]
\centering
\begin{tabular}{|c|p{4cm}|p{6cm}|}
\hline
\rowcolor{lightblue}
\textbf{Domaine} & \textbf{Technologie} & \textbf{Utilisation} \\
\hline
Backend & Python 3.x & Logique métier et traitement IA \\
\hline
Framework Web & FastAPI & API REST et WebSocket \\
\hline
Frontend & Vue.js 3 & Interface utilisateur réactive \\
\hline
Vision par Ordinateur & OpenCV & Traitement d'images et vidéos \\
\hline
Reconnaissance Faciale & Face Recognition & Détection et suivi des visages \\
\hline
Détection d'Objets & YOLOv8 & Identification des dispositifs \\
\hline
Gestes & MediaPipe & Traitement des mains (langue des signes) \\
\hline
Base de Données & ChromaDB & Stockage vectoriel des visages \\
\hline
Apprentissage Automatique & TensorFlow/Keras & Modèles d'IA personnalisés \\
\hline
\end{tabular}
\caption{Technologies principales utilisées dans le système}
\end{table}

\section{Architecture du Système}

\subsection{Vue d'Ensemble de l'Architecture}

Le système adopte une architecture web moderne séparant clairement l'interface utilisateur (frontend) du traitement des données (backend).

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=2.5cm,
    every node/.style={align=center, font=\small},
    frontend/.style={rectangle, draw=primaryblue, fill=lightblue, minimum width=3cm, minimum height=1.5cm, thick},
    backend/.style={rectangle, draw=darkgray, fill=lightgray, minimum width=3cm, minimum height=1.5cm, thick},
    ai/.style={rectangle, draw=orange, fill=orange!20, minimum width=2.5cm, minimum height=1.2cm, thick},
    db/.style={cylinder, draw=green, fill=green!20, minimum width=2.5cm, minimum height=1.2cm, shape border rotate=90, thick},
    camera/.style={ellipse, draw=red, fill=red!20, minimum width=2.5cm, minimum height=1cm, thick},
    connection/.style={->, thick, color=primaryblue}
]

% Main layers
\node[frontend] (frontend) {\textbf{Interface Web}\\Vue.js\\Affichage temps réel};
\node[backend, below=of frontend] (backend) {\textbf{Serveur Backend}\\FastAPI\\Traitement des données};

% AI modules
\node[ai, right=of backend] (emotion) {\textbf{Analyse Émotions}\\Détection faciale\\Classification};
\node[ai, below=of emotion] (device) {\textbf{Détection Objets}\\YOLOv8\\Identification};
\node[ai, below=of device] (sign) {\textbf{Langue des Signes}\\MediaPipe\\(En développement)};

% Data storage
\node[db, left=of backend] (facedb) {\textbf{Base Visages}\\ChromaDB\\Encodages};
\node[db, below=of facedb] (historydb) {\textbf{Historique}\\Données\\Statistiques};

% Camera input
\node[camera, above=of frontend] (camera) {\textbf{Caméra}\\Flux vidéo\\Capture temps réel};

% Connections
\draw[connection] (camera) -- (frontend);
\draw[connection] (frontend) -- node[left] {WebSocket} (backend);
\draw[connection] (backend) -- (emotion);
\draw[connection] (backend) -- (device);
\draw[connection] (backend) -- (sign);
\draw[connection, <->] (backend) -- (facedb);
\draw[connection, <->] (backend) -- (historydb);

\end{tikzpicture}
\caption{Architecture générale du système AI Learning Assistant}
\end{figure}

\subsection{Flux de Traitement des Données}

Le système suit un processus séquentiel pour analyser et traiter les données vidéo :

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=1.8cm,
    every node/.style={align=center, font=\footnotesize},
    process/.style={rectangle, draw=primaryblue, fill=lightblue, minimum width=2.2cm, minimum height=1cm, thick},
    decision/.style={diamond, draw=orange, fill=orange!20, minimum width=2cm, minimum height=1cm, thick},
    output/.style={ellipse, draw=green, fill=green!20, minimum width=2cm, minimum height=0.8cm, thick},
    flow/.style={->, thick, color=primaryblue}
]

% Main flow
\node[process] (capture) {\textbf{Capture}\\Flux vidéo};
\node[process, below=of capture] (preprocess) {\textbf{Préparation}\\Redimensionnement};
\node[decision, below=of preprocess] (detect) {\textbf{Détection}\\Visages ?};
\node[process, left=1.5cm of detect] (emotion) {\textbf{Analyse}\\Émotions};
\node[process, right=1.5cm of detect] (device) {\textbf{Détection}\\Objets};
\node[process, below=of detect] (store) {\textbf{Sauvegarde}\\Base de données};
\node[output, below=of store] (display) {\textbf{Affichage}\\Interface web};

% Flow connections
\draw[flow] (capture) -- (preprocess);
\draw[flow] (preprocess) -- (detect);
\draw[flow] (detect) -- node[above] {Oui} (emotion);
\draw[flow] (detect) -- node[above] {Toujours} (device);
\draw[flow] (emotion) -- (store);
\draw[flow] (device) -- (store);
\draw[flow] (store) -- (display);

\end{tikzpicture}
\caption{Workflow de traitement des données en temps réel}
\end{figure}

\section{Fonctionnalités Principales}

\subsection{Suivi des Étudiants et Analyse Émotionnelle}

Le système offre un suivi sophistiqué des étudiants avec les fonctionnalités suivantes :

\subsubsection{Détection et Reconnaissance Faciale}
\begin{itemize}
    \item \textbf{Détection automatique} : Identification des visages dans le flux vidéo
    \item \textbf{Reconnaissance biométrique} : Suivi unique de chaque étudiant
    \item \textbf{Encodage vectoriel} : Stockage efficient des caractéristiques faciales
    \item \textbf{Persistance} : Reconnaissance des étudiants entre les sessions
\end{itemize}

\subsubsection{Analyse Émotionnelle}
Le système analyse les émotions en temps réel :

\begin{table}[H]
\centering
\begin{tabular}{|c|p{3cm}|p{5cm}|}
\hline
\rowcolor{lightblue}
\textbf{Émotion} & \textbf{Indicateur} & \textbf{Impact sur la Concentration} \\
\hline
Heureux & \textcolor{green}{} & Concentration élevée (70-90\%) \\
\hline
Neutre & \textcolor{orange}{} & Concentration moyenne (40-70\%) \\
\hline
Concentré & \textcolor{green}{} & Concentration maximale (80-100\%) \\
\hline
Triste & \textcolor{red}{} & Concentration faible (20-40\%) \\
\hline
Surpris & \textcolor{orange}{} & Concentration variable (30-60\%) \\
\hline
\end{tabular}
\caption{Correspondance entre émotions et niveaux de concentration}
\end{table}

\subsection{Détection d'Objets et Gestion des Distractions}

\subsubsection{Détection Basée sur YOLO}
Le système utilise YOLOv8 pour détecter les objets potentiellement perturbateurs :

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=1.5cm,
    every node/.style={align=center, font=\footnotesize},
    device/.style={rectangle, draw, fill=lightblue, minimum width=2cm, minimum height=1cm},
    level/.style={rectangle, draw, minimum width=1.5cm, minimum height=0.8cm}
]

% Devices
\node[device] (phone) {Téléphone\\Portable};
\node[device, right=of phone] (laptop) {Ordinateur\\Portable};
\node[device, right=of laptop] (tablet) {Tablette};
\node[device, below=of phone] (book) {Livre};
\node[device, right=of book] (mouse) {Souris};
\node[device, right=of mouse] (keyboard) {Clavier};

% Distraction levels
\node[level, fill=red!30, below=2cm of laptop] (high) {Élevée};
\node[level, fill=orange!30, left=of high] (medium) {Moyenne};
\node[level, fill=green!30, right=of high] (low) {Faible};

% Connections
\draw[->, thick, red] (phone) -- (high);
\draw[->, thick, orange] (laptop) -- (medium);
\draw[->, thick, orange] (tablet) -- (medium);
\draw[->, thick, green] (book) -- (low);
\draw[->, thick, green] (mouse) -- (low);
\draw[->, thick, green] (keyboard) -- (low);

\end{tikzpicture}
\caption{Classification des dispositifs selon leur niveau de distraction}
\end{figure}

\subsubsection{Système de Scoring}
Le système calcule un score de distraction basé sur :
\begin{itemize}
    \item Nombre d'objets détectés
    \item Type d'objets (téléphone = score élevé, livre = score faible)
    \item Durée de présence des objets
    \item Fréquence d'apparition
\end{itemize}

\subsection{Interface Utilisateur et Tableaux de Bord}

\subsubsection{Interface Principale}
L'interface propose deux onglets principaux :

\begin{enumerate}
    \item \textbf{Suivi de Concentration} : Monitoring en temps réel des étudiants
    \item \textbf{Traduction Langue des Signes} : Fonctionnalité en développement
\end{enumerate}

\subsubsection{Statistiques et Métriques}
Le système fournit des métriques complètes :

\begin{figure}[H]
\centering
\begin{tikzpicture}
\begin{axis}[
    width=10cm,
    height=6cm,
    xlabel={Temps (minutes)},
    ylabel={Concentration (\%)},
    title={Évolution de la Concentration Moyenne},
    grid=major,
    legend pos=north east,
    xmin=0, xmax=60,
    ymin=0, ymax=100
]

\addplot[color=green, thick] coordinates {
    (0,75) (10,78) (20,72) (30,68) (40,71) (50,74) (60,77)
};
\addlegendentry{Concentration Moyenne}

\addplot[color=orange, thick] coordinates {
    (0,65) (10,70) (20,63) (30,58) (40,62) (50,67) (60,69)
};
\addlegendentry{Seuil Acceptable}

\end{axis}
\end{tikzpicture}
\caption{Exemple d'évolution de la concentration sur une session}
\end{figure}

\subsection{Traduction de Langue des Signes (En Développement)}

\subsubsection{État Actuel}
La fonctionnalité de traduction de langue des signes est actuellement en phase de développement avec les composants suivants :

\begin{itemize}
    \item \textbf{Détection des mains} : Utilisation de MediaPipe pour l'identification des landmarks
    \item \textbf{Extraction des caractéristiques} : Conversion des positions en vecteurs
    \item \textbf{Modèle de classification} : Réseau LSTM pour la reconnaissance des signes
    \item \textbf{Interface temps réel} : Affichage des traductions en direct
\end{itemize}

\subsubsection{Défis Techniques}
Les principaux défis incluent :
\begin{itemize}
    \item Précision de la détection des gestes
    \item Gestion des variations individuelles
    \item Traitement en temps réel
    \item Création d'un dataset d'entraînement
\end{itemize}

\section{Architecture Backend}

\subsection{Responsabilités du Backend}

Le backend FastAPI gère les responsabilités critiques suivantes :

\subsubsection{Traitement de l'Intelligence Artificielle}
\begin{itemize}
    \item \textbf{Détection faciale} : Utilisation de la bibliothèque face\_recognition
    \item \textbf{Analyse émotionnelle} : Modèles de deep learning pour classifier les émotions
    \item \textbf{Détection d'objets} : Intégration YOLOv8 pour identifier les dispositifs
    \item \textbf{Traitement des signes} : MediaPipe pour l'analyse des gestes (en développement)
\end{itemize}

\subsubsection{Gestion des Données}
\begin{itemize}
    \item \textbf{Base vectorielle} : ChromaDB pour stocker les encodages faciaux
    \item \textbf{Historique} : Sauvegarde des détections et statistiques
    \item \textbf{Persistance} : Gestion des sessions et données utilisateurs
    \item \textbf{Export} : Fonctionnalités d'export des données JSON
\end{itemize}

\subsection{Modules Backend}

\subsubsection{Module de Détection Émotionnelle}
Le module de détection émotionnelle analyse les expressions faciales des étudiants pour évaluer leur état émotionnel et leur niveau de concentration. Il utilise des modèles de deep learning pour identifier les émotions principales et calculer un score de concentration basé sur ces analyses.

\subsubsection{Module de Détection de Dispositifs}
Le module de détection de dispositifs utilise l'algorithme YOLO pour identifier les objets potentiellement perturbateurs dans l'environnement d'apprentissage. Il attribue des scores de distraction différents selon le type d'objet détecté et maintient un historique des détections pour l'analyse statistique.

\subsection{API RESTful}

Le backend expose une API RESTful complète :

\begin{table}[H]
\centering
\footnotesize
\begin{tabular}{|l|l|p{5cm}|}
\hline
\rowcolor{lightblue}
\textbf{Endpoint} & \textbf{Méthode} & \textbf{Description} \\
\hline
/faces & GET & Récupère tous les visages suivis \\
\hline
/faces/\{id\} & GET & Détails d'un visage spécifique \\
\hline
/statistics & GET & Statistiques globales du système \\
\hline
/camera/start & POST & Démarre la capture vidéo \\
\hline
/camera/stop & POST & Arrête la capture vidéo \\
\hline
/devices & GET & Compte actuel des dispositifs \\
\hline
/devices/history & GET & Historique des détections \\
\hline
/api/devices/toggle-tracking & POST & Active/désactive le suivi \\
\hline
/api/system/reset-all-data & POST & Réinitialise toutes les données \\
\hline
/ws & WebSocket & Communication temps réel \\
\hline
/ws/signlanguage & WebSocket & Traduction langue des signes \\
\hline
\end{tabular}
\caption{Endpoints API principaux}
\end{table}

\subsection{Communication WebSocket}

Le système utilise WebSockets pour la communication temps réel :

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=2cm,
    every node/.style={align=center, font=\footnotesize},
    client/.style={rectangle, draw, fill=lightblue, minimum width=2cm, minimum height=1cm},
    server/.style={rectangle, draw, fill=lightgray, minimum width=2cm, minimum height=1cm},
    message/.style={->, thick, color=primaryblue}
]

\node[client] (frontend) {Frontend\\Vue.js};
\node[server, right=4cm of frontend] (backend) {Backend\\FastAPI};

% Messages
\draw[message] (frontend) -- node[above] {Connexion} (backend);
\draw[message] (backend) -- node[below] {Confirmation} (frontend);
\draw[message] (backend) -- node[above, pos=0.7] {Détections} (frontend);
\draw[message] (backend) -- node[below, pos=0.7] {Statistiques} (frontend);
\draw[message] (backend) -- node[above, pos=0.3] {Frames} (frontend);

\end{tikzpicture}
\caption{Communication WebSocket bidirectionnelle}
\end{figure}

\section{Architecture Frontend}

\subsection{Responsabilités du Frontend}

Le frontend Vue.js gère l'interface utilisateur avec les responsabilités suivantes :

\subsubsection{Interface Utilisateur}
\begin{itemize}
    \item \textbf{Affichage temps réel} : Flux vidéo avec annotations
    \item \textbf{Tableaux de bord} : Statistiques et métriques visuelles
    \item \textbf{Contrôles} : Gestion des fonctionnalités du système
    \item \textbf{Modals} : Détails des étudiants et historiques
\end{itemize}

\subsubsection{Gestion des États}
\begin{itemize}
    \item \textbf{Réactivité} : Mise à jour automatique des données
    \item \textbf{Persistence} : Sauvegarde locale des préférences
    \item \textbf{Synchronisation} : Cohérence avec le backend
    \item \textbf{Navigation} : Gestion des onglets et vues
\end{itemize}

\subsection{Composants Principaux}

\subsubsection{Composant de Suivi}
Le composant principal de suivi gère l'affichage du flux vidéo en temps réel avec des annotations visuelles. Il présente les statistiques actuelles sous forme de cartes informatives et offre des contrôles pour démarrer ou arrêter la caméra. L'interface est conçue pour être intuitive et réactive, avec des mises à jour automatiques des données.

\subsubsection{Gestion des WebSockets}
La communication en temps réel utilise les WebSockets pour maintenir une connexion persistante avec le backend. Le système gère automatiquement les reconnexions en cas de perte de connexion et traite les différents types de messages : détections, statistiques et frames vidéo. Cette architecture garantit une expérience utilisateur fluide et des mises à jour instantanées.

\subsection{Design System et UI/UX}

\subsubsection{Palette de Couleurs}
Le système utilise une palette cohérente :

\begin{figure}[H]
\centering
\begin{tikzpicture}
\node[fill=primaryblue, text=white, minimum width=2cm, minimum height=1cm] at (0,0) {Primary};
\node[fill=secondaryblue, text=white, minimum width=2cm, minimum height=1cm] at (2.5,0) {Secondary};
\node[fill=green, text=white, minimum width=2cm, minimum height=1cm] at (5,0) {Success};
\node[fill=orange, text=white, minimum width=2cm, minimum height=1cm] at (7.5,0) {Warning};
\node[fill=red, text=white, minimum width=2cm, minimum height=1cm] at (10,0) {Danger};
\end{tikzpicture}
\caption{Palette de couleurs du système}
\end{figure}

\subsubsection{Composants Réutilisables}
\begin{itemize}
    \item \textbf{Cards} : Conteneurs d'information standardisés
    \item \textbf{Buttons} : Boutons avec états et variantes
    \item \textbf{Modals} : Fenêtres contextuelles pour détails
    \item \textbf{Charts} : Graphiques interactifs avec Chart.js
\end{itemize}

\section{Flux de Données et Communication}

\subsection{Architecture de Communication}

\begin{figure}[H]
\centering
\begin{tikzpicture}[
    node distance=2cm,
    every node/.style={align=center, font=\footnotesize},
    frontend/.style={rectangle, draw, fill=lightblue, minimum width=2.5cm, minimum height=1.5cm},
    backend/.style={rectangle, draw, fill=lightgray, minimum width=2.5cm, minimum height=1.5cm},
    ai/.style={rectangle, draw, fill=orange!30, minimum width=2cm, minimum height=1cm},
    db/.style={cylinder, draw, fill=green!30, minimum width=2cm, minimum height=1cm, shape border rotate=90},
    flow/.style={<->, thick, color=primaryblue},
    data/.style={->, thick, color=green}
]

% Main components
\node[frontend] (fe) {Frontend\\Vue.js\\Interface};
\node[backend, right=4cm of fe] (be) {Backend\\FastAPI\\API};

% AI Components
\node[ai, above=1.5cm of be] (emotion) {Détection\\Émotions};
\node[ai, right=1.5cm of be] (device) {Détection\\Dispositifs};
\node[ai, below=1.5cm of be] (sign) {Langue\\Signes};

% Databases
\node[db, right=3cm of device] (facedb) {Base\\Visages};
\node[db, below=of facedb] (historydb) {Historique\\Données};

% Connections
\draw[flow] (fe) -- node[above] {WebSocket/HTTP} (be);
\draw[data] (be) -- (emotion);
\draw[data] (be) -- (device);
\draw[data] (be) -- (sign);
\draw[data] (emotion) -- (facedb);
\draw[data] (device) -- (historydb);

\end{tikzpicture}
\caption{Architecture de communication entre composants}
\end{figure}

\subsection{Protocoles de Communication}

\subsubsection{WebSocket (Temps Réel)}
\begin{itemize}
    \item \textbf{Détections} : Streaming des analyses en temps réel
    \item \textbf{Statistiques} : Mise à jour continue des métriques
    \item \textbf{Frames} : Transmission du flux vidéo traité
    \item \textbf{Statuts} : Informations sur l'état du système
\end{itemize}

\subsubsection{API REST (Actions)}
\begin{itemize}
    \item \textbf{Configuration} : Paramètres du système
    \item \textbf{Contrôles} : Démarrage/arrêt des fonctionnalités
    \item \textbf{Historique} : Consultation des données passées
    \item \textbf{Export} : Téléchargement des données
\end{itemize}

\section{Performances et Optimisations}

\subsection{Optimisations Backend}

\subsubsection{Traitement Vidéo}
\begin{itemize}
    \item \textbf{Échantillonnage} : Traitement d'une frame sur 5 pour réduire la charge CPU
    \item \textbf{Redimensionnement} : Adaptation de la résolution selon les besoins
    \item \textbf{Compression} : Optimisation des images transmises
    \item \textbf{Threading} : Traitement asynchrone des tâches lourdes
\end{itemize}

\subsubsection{Gestion Mémoire}
\begin{itemize}
    \item \textbf{Garbage Collection} : Nettoyage automatique des objets temporaires
    \item \textbf{Buffers circulaires} : Limitation des données en mémoire
    \item \textbf{Compression des encodings} : Optimisation du stockage vectoriel
\end{itemize}

\subsection{Optimisations Frontend}

\subsubsection{Réactivité}
\begin{itemize}
    \item \textbf{Lazy Loading} : Chargement différé des composants
    \item \textbf{Debouncing} : Limitation des requêtes fréquentes
    \item \textbf{Pagination} : Affichage par chunks des grandes listes
    \item \textbf{Caching} : Mise en cache des données statiques
\end{itemize}

\section{Conclusion}

\subsection{Bilan du Projet}

L'AI Learning Assistant représente une solution innovante pour le monitoring intelligent des environnements d'apprentissage. Le système combine avec succès :

\begin{itemize}
    \item \textbf{Technologies avancées} : IA, vision par ordinateur, développement web moderne
    \item \textbf{Interface intuitive} : Expérience utilisateur optimisée avec Vue.js
    \item \textbf{Performance} : Traitement temps réel avec optimisations
    \item \textbf{Extensibilité} : Architecture modulaire et évolutive
\end{itemize}

\subsection{Fonctionnalités Principales}

Le système offre actuellement :

\begin{itemize}
    \item \textbf{Suivi des étudiants} : Détection et reconnaissance faciale en temps réel
    \item \textbf{Analyse émotionnelle} : Évaluation de l'engagement et de la concentration
    \item \textbf{Détection d'objets} : Identification des dispositifs potentiellement perturbateurs
    \item \textbf{Interface web moderne} : Tableau de bord intuitif et responsive
    \item \textbf{Communication temps réel} : WebSockets pour les mises à jour instantanées
\end{itemize}

\subsection{Développements Futurs}

Le projet évolue vers :

\begin{itemize}
    \item \textbf{Finalisation du module de langue des signes} : Actuellement en développement
    \item \textbf{Amélioration des modèles IA} : Précision et performance accrues
    \item \textbf{Extensions fonctionnelles} : Nouvelles capacités d'analyse
    \item \textbf{Optimisations} : Performance et scalabilité améliorées
\end{itemize}

\subsection{Impact Attendu}

Le système vise à transformer l'expérience éducative en offrant :

\begin{itemize}
    \item \textbf{Aux enseignants} : Outils d'analyse et de suivi objectifs
    \item \textbf{Aux étudiants} : Feedback personnalisé sur leur engagement
    \item \textbf{Aux institutions} : Données analytiques pour l'amélioration continue
    \item \textbf{À la recherche} : Plateforme pour l'innovation pédagogique
\end{itemize}

\vspace{2cm}

\hrule

\vspace{0.5cm}

\begin{center}
\textbf{\large AI Learning Assistant}\\
\textcolor{darkgray}{Système Intelligent de Suivi des Étudiants}\\
\textcolor{darkgray}{\small Version 1.0 - \today}
\end{center}

\end{document}
